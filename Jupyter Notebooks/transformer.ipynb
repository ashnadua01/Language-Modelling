{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-10T18:15:34.745184Z","iopub.status.busy":"2024-09-10T18:15:34.744244Z","iopub.status.idle":"2024-09-10T18:15:34.751246Z","shell.execute_reply":"2024-09-10T18:15:34.750270Z","shell.execute_reply.started":"2024-09-10T18:15:34.745142Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn, optim\n","from torch.utils.data import DataLoader, Dataset\n","import torch.nn.functional as F\n","import numpy as np\n","import re\n","import nltk\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","import random\n","import time\n","from tqdm import tqdm\n","from torch.nn.utils.rnn import pad_sequence"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:15:35.216971Z","iopub.status.busy":"2024-09-10T18:15:35.216610Z","iopub.status.idle":"2024-09-10T18:15:35.333609Z","shell.execute_reply":"2024-09-10T18:15:35.332674Z","shell.execute_reply.started":"2024-09-10T18:15:35.216934Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["nltk.download('punkt')"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:15:36.942762Z","iopub.status.busy":"2024-09-10T18:15:36.942394Z","iopub.status.idle":"2024-09-10T18:15:36.948755Z","shell.execute_reply":"2024-09-10T18:15:36.947630Z","shell.execute_reply.started":"2024-09-10T18:15:36.942727Z"},"trusted":true},"outputs":[],"source":["def preprocess(data):\n","    data = re.sub(r'\\n|\\s+', ' ', data) #newline and multiple spaces -> single space\n","    data = re.sub(r'[’‘]', '\\'', data) #apostrophes\n","    data = re.sub(r'[“”`\\' ]|[–—-]', ' ', data) #quotes and dashes\n","    data = re.sub(r'(?<!\\w)([.!?])(?!\\w)', r' \\1 ', data) #dont remove punctuation\n","    data = re.sub(r'[™•]', ' ', data) #remove other unwanted symbols\n","    return data.strip() #strip extra spaces"]},{"cell_type":"markdown","metadata":{},"source":["## Tokenization"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:15:38.664212Z","iopub.status.busy":"2024-09-10T18:15:38.663672Z","iopub.status.idle":"2024-09-10T18:15:38.676120Z","shell.execute_reply":"2024-09-10T18:15:38.674836Z","shell.execute_reply.started":"2024-09-10T18:15:38.664174Z"},"trusted":true},"outputs":[],"source":["def tokenize(data, min_length_sentences):\n","    sentences = sent_tokenize(data)\n","    sentences = [sentence for sentence in sentences if len(sentence.split()) >= min_length_sentences]\n","    \n","    print(\"Length of sentences:\", len(sentences))\n","\n","    words_sentences = []\n","\n","    for sentence in sentences:\n","        words = word_tokenize(sentence)\n","        words = [word.lower() for word in words if word.lower() not in ['.', ',', '!', '?', ';', ':']]\n","        words = ['<s>'] + words + ['</s>']\n","        words_sentences.append(words)\n","    \n","    return sentences, words_sentences"]},{"cell_type":"markdown","metadata":{},"source":["## Data Preparation"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:15:39.963950Z","iopub.status.busy":"2024-09-10T18:15:39.963564Z","iopub.status.idle":"2024-09-10T18:15:39.970952Z","shell.execute_reply":"2024-09-10T18:15:39.969953Z","shell.execute_reply.started":"2024-09-10T18:15:39.963914Z"},"trusted":true},"outputs":[],"source":["def train_val_test_split(sentences, train_ratio=0.7, val_ratio=0.2, seed=None, num_shuffles=1):\n","    if seed is not None:\n","        random.seed(seed)\n","    \n","    for _ in range(num_shuffles):\n","        random.shuffle(sentences)\n","    \n","    total_sentences = len(sentences)\n","    \n","    train_size = int(total_sentences * train_ratio)\n","    val_size = int(total_sentences * val_ratio)\n","    test_size = total_sentences - train_size - val_size\n","    \n","    train_sentences = sentences[:train_size]\n","    val_sentences = sentences[train_size:train_size + val_size]\n","    test_sentences = sentences[train_size + val_size:]\n","    \n","    return train_sentences, val_sentences, test_sentences\n"]},{"cell_type":"markdown","metadata":{},"source":["## Loading Glove Embeddings"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:15:41.250445Z","iopub.status.busy":"2024-09-10T18:15:41.250040Z","iopub.status.idle":"2024-09-10T18:15:41.257561Z","shell.execute_reply":"2024-09-10T18:15:41.256393Z","shell.execute_reply.started":"2024-09-10T18:15:41.250406Z"},"trusted":true},"outputs":[],"source":["def create_glove_embeddings(glove_path):\n","    glove = {}\n","    embedding_dim = 0\n","\n","    with open(glove_path, 'r') as f:\n","        for line in f:\n","            values = line.split()\n","            word = values[0]\n","            vector = torch.tensor([float(val) for val in values[1:]])\n","            glove[word] = vector\n","            embedding_dim = len(values[1:])\n","\n","    glove['<UNK>'] = torch.mean(torch.stack(list(glove.values())), dim=0)\n","    glove['<PAD>'] = torch.zeros(embedding_dim)\n","    glove['<s>'] = torch.rand(embedding_dim)\n","    glove['</s>'] = torch.rand(embedding_dim)\n","\n","    return glove"]},{"cell_type":"markdown","metadata":{},"source":["## Creation of Vocab and Embeddings"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:15:42.651605Z","iopub.status.busy":"2024-09-10T18:15:42.651214Z","iopub.status.idle":"2024-09-10T18:15:42.661975Z","shell.execute_reply":"2024-09-10T18:15:42.661014Z","shell.execute_reply.started":"2024-09-10T18:15:42.651569Z"},"trusted":true},"outputs":[],"source":["def create_embeddings_and_encode(train_sentences, val_sentences, test_sentences, glove):\n","    embedding_dim = len(list(glove.values())[0])\n","    vocab = set()\n","\n","    vocab.update(['<UNK>', '<PAD>', '<s>', '</s>'])\n","    for sentence in train_sentences:\n","        for word in sentence:\n","            if word in glove:\n","                vocab.add(word)\n","            else:\n","                sentence[sentence.index(word)] = '<UNK>' \n","                \n","    embeddings = np.zeros((len(vocab), embedding_dim))\n","    word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n","\n","    for word in vocab:\n","        if word in glove:\n","            embeddings[word_to_idx[word]] = glove[word]\n","        else:\n","            embeddings[word_to_idx[word]] = np.random.rand(embedding_dim)\n","\n","    def encode_sentences(sentences, word_to_idx):\n","        encoded_sentences = []\n","        for sentence in sentences:\n","            encoded_sentence = [word_to_idx[word] if word in word_to_idx else word_to_idx['<UNK>'] for word in sentence]\n","            encoded_sentences.append(encoded_sentence)\n","        return encoded_sentences\n","\n","    encoded_train_sentences = encode_sentences(train_sentences, word_to_idx)\n","    encoded_val_sentences = encode_sentences(val_sentences, word_to_idx)\n","    encoded_test_sentences = encode_sentences(test_sentences, word_to_idx)\n","\n","    return torch.FloatTensor(embeddings), encoded_train_sentences, encoded_val_sentences, encoded_test_sentences, word_to_idx, list(vocab)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Datatset for Training Transformer"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:15:44.438818Z","iopub.status.busy":"2024-09-10T18:15:44.438421Z","iopub.status.idle":"2024-09-10T18:15:44.445355Z","shell.execute_reply":"2024-09-10T18:15:44.444198Z","shell.execute_reply.started":"2024-09-10T18:15:44.438782Z"},"trusted":true},"outputs":[],"source":["class TransformerDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        sentence = self.data[idx]\n","        input_sentence = torch.tensor(sentence[:-1], dtype=torch.long)\n","        target = torch.tensor(sentence[1:], dtype=torch.long)\n","        return input_sentence, target"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:15:45.447966Z","iopub.status.busy":"2024-09-10T18:15:45.447136Z","iopub.status.idle":"2024-09-10T18:15:45.453243Z","shell.execute_reply":"2024-09-10T18:15:45.452134Z","shell.execute_reply.started":"2024-09-10T18:15:45.447920Z"},"trusted":true},"outputs":[],"source":["def collate_fn(batch, pad_idx):\n","    input_sentences, targets = zip(*batch)\n","    input_sentences = pad_sequence(input_sentences, batch_first=True, padding_value=pad_idx)\n","    targets = pad_sequence(targets, batch_first=True, padding_value=pad_idx)\n","    return input_sentences, targets\n"]},{"cell_type":"markdown","metadata":{},"source":["## Transformer"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:15:48.249131Z","iopub.status.busy":"2024-09-10T18:15:48.248424Z","iopub.status.idle":"2024-09-10T18:15:48.255787Z","shell.execute_reply":"2024-09-10T18:15:48.254725Z","shell.execute_reply.started":"2024-09-10T18:15:48.249089Z"},"trusted":true},"outputs":[],"source":["def pos_encoding(num_tokens, n_dim):\n","    pos_enc = np.zeros((num_tokens, n_dim))\n","    positions = np.arange(num_tokens)[:, np.newaxis]\n","    div_term = np.exp(np.arange(0, n_dim, 2) * -(np.log(10000.0) / n_dim))\n","    pos_enc[:, 0::2] = np.sin(positions * div_term)\n","    pos_enc[:, 1::2] = np.cos(positions * div_term)\n","    return torch.tensor(pos_enc, dtype=torch.float)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:15:49.384638Z","iopub.status.busy":"2024-09-10T18:15:49.384259Z","iopub.status.idle":"2024-09-10T18:15:49.393175Z","shell.execute_reply":"2024-09-10T18:15:49.392294Z","shell.execute_reply.started":"2024-09-10T18:15:49.384601Z"},"trusted":true},"outputs":[],"source":["class TransformerDecoder(nn.Module):\n","    def __init__(self, embedding, vocab_size, embedding_dim, num_heads, num_layers, hidden_dim, dropout=0.1):\n","        super(TransformerDecoder, self).__init__()\n","        \n","        self.embedding = nn.Embedding.from_pretrained(embedding, freeze=True)\n","        self.positional_encoding = pos_encoding(200, embedding_dim).to(device)\n","        \n","        decoder_layer = nn.TransformerDecoderLayer(d_model=embedding_dim, nhead=num_heads, dim_feedforward=hidden_dim, dropout=dropout)\n","        \n","        self.transformer_decoder = nn.TransformerDecoder(decoder_layer=decoder_layer,num_layers=num_layers)\n","        \n","        self.fc_out = nn.Linear(embedding_dim, vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","        self.layer_norm = nn.LayerNorm(embedding_dim)\n","    \n","    def forward(self, tgt, tgt_mask=None):\n","        tgt = self.embedding(tgt) + self.positional_encoding[:tgt.size(1)]\n","        tgt = self.layer_norm(tgt)\n","        output = self.transformer_decoder(tgt, memory=tgt, tgt_mask=tgt_mask)  # Use tgt as memory\n","        output = self.fc_out(self.dropout(output))\n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["## Model Testing"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:15:51.850396Z","iopub.status.busy":"2024-09-10T18:15:51.850050Z","iopub.status.idle":"2024-09-10T18:15:51.856844Z","shell.execute_reply":"2024-09-10T18:15:51.855911Z","shell.execute_reply.started":"2024-09-10T18:15:51.850365Z"},"trusted":true},"outputs":[],"source":["def test_model_transformer(model, val_loader, criterion, pad_idx):\n","    model.eval()\n","    total_loss = 0\n","\n","    with torch.no_grad():\n","        for x, y in val_loader:\n","            x, y = x.to(device), y.to(device)\n","\n","            output = model(x)\n","            loss = criterion(output.view(-1, output.shape[2]), y.view(-1)) \n","            total_loss += loss.item()\n","\n","    avg_val_loss = total_loss / len(val_loader)\n","    val_perplexity = torch.exp(torch.tensor(avg_val_loss))\n","    return avg_val_loss, val_perplexity\n"]},{"cell_type":"markdown","metadata":{},"source":["## Train Model"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:15:53.463274Z","iopub.status.busy":"2024-09-10T18:15:53.462879Z","iopub.status.idle":"2024-09-10T18:15:53.473930Z","shell.execute_reply":"2024-09-10T18:15:53.472873Z","shell.execute_reply.started":"2024-09-10T18:15:53.463229Z"},"trusted":true},"outputs":[],"source":["def train_model_transformer(model, train_loader, val_loader, optimizer, criterion, scheduler, num_epochs, patience=2, pad_idx=0):\n","    model.to(device)\n","    early_stopping_counter = 0\n","    best_val_loss = float('inf')\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        total_loss = 0\n","\n","        for x, y in tqdm(train_loader):\n","            x, y = x.to(device), y.to(device)\n","            optimizer.zero_grad()\n","\n","            output = model(x)\n","            loss = criterion(output.view(-1, output.shape[2]), y.view(-1)) \n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","\n","        avg_train_loss = total_loss / len(train_loader)\n","        perplexity = torch.exp(torch.tensor(avg_train_loss))\n","\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print(f'Train Loss: {avg_train_loss:.4f}')\n","        print(f'Train Perplexity: {perplexity:.4f}')\n","\n","        avg_val_loss, val_perplexity = test_model_transformer(model, val_loader, criterion, pad_idx)\n","        print(f'Val Loss: {avg_val_loss:.4f}')\n","        print(f'Val Perplexity: {val_perplexity:.4f}')\n","\n","        scheduler.step(avg_val_loss)\n","        \n","        if avg_val_loss < best_val_loss:\n","            best_val_loss = avg_val_loss\n","            early_stopping_counter = 0\n","            torch.save(model.state_dict(), '2021101072_LM3.pt')\n","        else:\n","            early_stopping_counter += 1\n","            if early_stopping_counter >= patience:\n","                print(f'Early stopping at epoch {epoch + 1}')\n","                break\n","\n","    return model\n"]},{"cell_type":"markdown","metadata":{},"source":["## Save Perplexities in files"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:15:54.966031Z","iopub.status.busy":"2024-09-10T18:15:54.965636Z","iopub.status.idle":"2024-09-10T18:15:54.978518Z","shell.execute_reply":"2024-09-10T18:15:54.977464Z","shell.execute_reply.started":"2024-09-10T18:15:54.965971Z"},"trusted":true},"outputs":[],"source":["def save_perplexities_transformer(model, sentences, criterion, filename, idx_to_word, pad_idx):\n","    model.eval()\n","    total_loss = 0\n","    all_sentences = []\n","    perplexity_scores = []\n","\n","    with torch.no_grad():\n","        for sentence in sentences:\n","            sentence_loss = 0\n","            sentence_length = 0\n","            input_indices = sentence[:-1]\n","            target_indices = sentence[1:]\n","\n","            input_tensor = torch.tensor(input_indices, dtype=torch.long).unsqueeze(0).to(device)\n","            targets = torch.tensor(target_indices, dtype=torch.long).to(device)\n","\n","            outputs = model(input_tensor)\n","\n","            for i in range(outputs.shape[1]):\n","                output = outputs[0, i]\n","                target_word = targets[i]\n","\n","                if target_word != pad_idx:\n","                    loss = criterion(output.unsqueeze(0), target_word.unsqueeze(0))\n","                    sentence_loss += loss.item()\n","                    sentence_length += 1\n","\n","            if sentence_length > 0:\n","                avg_loss_per_sentence = sentence_loss / sentence_length\n","                sentence_perplexity = torch.exp(torch.tensor(avg_loss_per_sentence)).item()\n","            else:\n","                sentence_perplexity = float('inf')  # handle empty sentences (unlikely, but a safeguard)\n","\n","            perplexity_scores.append(sentence_perplexity)\n","            sentence_words = [idx_to_word[idx] for idx in sentence]\n","            full_sentence = \" \".join(sentence_words)\n","            all_sentences.append(full_sentence)\n","\n","        avg_perplexity = sum(perplexity_scores) / len(perplexity_scores)\n","\n","    with open(filename, 'w') as f:\n","        for i, sentence in enumerate(all_sentences):\n","            f.write(f\"{sentence}\\t{perplexity_scores[i]:.4f}\\n\")\n","        \n","        f.write(f\"Average\\t{avg_perplexity:.4f}\\n\")\n","\n","    return avg_perplexity\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:15:55.709888Z","iopub.status.busy":"2024-09-10T18:15:55.709493Z","iopub.status.idle":"2024-09-10T18:15:55.714911Z","shell.execute_reply":"2024-09-10T18:15:55.713788Z","shell.execute_reply.started":"2024-09-10T18:15:55.709849Z"},"trusted":true},"outputs":[],"source":["def save_model(model, path):\n","    torch.save(model.state_dict(), path)\n","    print(f\"Model saved to {path}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Running the Model"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:15:57.417139Z","iopub.status.busy":"2024-09-10T18:15:57.416773Z","iopub.status.idle":"2024-09-10T18:15:57.472788Z","shell.execute_reply":"2024-09-10T18:15:57.471801Z","shell.execute_reply.started":"2024-09-10T18:15:57.417104Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:15:58.837788Z","iopub.status.busy":"2024-09-10T18:15:58.837021Z","iopub.status.idle":"2024-09-10T18:16:16.591076Z","shell.execute_reply":"2024-09-10T18:16:16.590158Z","shell.execute_reply.started":"2024-09-10T18:15:58.837750Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of sentences: 57178\n","Train size: 40024\n","Validation size: 11435\n","Test size: 5719\n"]}],"source":["with open('/kaggle/input/auguste-maquet/Auguste_Maquet.txt', 'r') as f:\n","    corpus = f.read()\n","    \n","corpus = preprocess(corpus) \n","\n","sentences, word_sentences = tokenize(corpus, 2)\n","\n","train_sentences, val_sentences, test_sentences = train_val_test_split(word_sentences)\n","\n","print(\"Train size:\", len(train_sentences))\n","print(\"Validation size:\", len(val_sentences))\n","print(\"Test size:\", len(test_sentences))"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:16:16.593597Z","iopub.status.busy":"2024-09-10T18:16:16.592908Z","iopub.status.idle":"2024-09-10T18:17:27.297438Z","shell.execute_reply":"2024-09-10T18:17:27.296568Z","shell.execute_reply.started":"2024-09-10T18:16:16.593552Z"},"trusted":true},"outputs":[],"source":["glove = create_glove_embeddings('/kaggle/input/glove-300/glove.6B.300d.txt')\n","\n","embeddings, encoded_train, encoded_val, encoded_test, word_to_idx, vocab = create_embeddings_and_encode(train_sentences, val_sentences, test_sentences, glove)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:17:52.138299Z","iopub.status.busy":"2024-09-10T18:17:52.137538Z","iopub.status.idle":"2024-09-10T18:17:52.147891Z","shell.execute_reply":"2024-09-10T18:17:52.146822Z","shell.execute_reply.started":"2024-09-10T18:17:52.138259Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train dataset size: 40024\n","Validation dataset size: 11435\n","Test dataset size: 5719\n"]}],"source":["pad_idx = word_to_idx['<PAD>']\n","\n","train_dataset = TransformerDataset(encoded_train)\n","val_dataset = TransformerDataset(encoded_val)\n","test_dataset = TransformerDataset(encoded_test)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, collate_fn=lambda batch: collate_fn(batch, pad_idx), shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, collate_fn=lambda batch: collate_fn(batch, pad_idx), shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, collate_fn=lambda batch: collate_fn(batch, pad_idx), shuffle=True)\n","\n","print(f'Train dataset size: {len(train_dataset)}')\n","print(f'Validation dataset size: {len(val_dataset)}')\n","print(f'Test dataset size: {len(test_dataset)}')"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:17:53.996258Z","iopub.status.busy":"2024-09-10T18:17:53.995638Z","iopub.status.idle":"2024-09-10T18:17:55.541931Z","shell.execute_reply":"2024-09-10T18:17:55.541166Z","shell.execute_reply.started":"2024-09-10T18:17:53.996210Z"},"trusted":true},"outputs":[],"source":["vocab_size = len(vocab)\n","embedding_dim = 300\n","num_heads = 10\n","num_layers = 2\n","hidden_dim = 300\n","dropout = 0.1\n","\n","model = TransformerDecoder(embedding=embeddings, vocab_size=vocab_size, embedding_dim=embedding_dim, num_heads=num_heads, num_layers=num_layers, hidden_dim=hidden_dim, dropout=dropout)\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n","optimizer = optim.AdamW(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=0, factor=0.1)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:18:03.574023Z","iopub.status.busy":"2024-09-10T18:18:03.573036Z","iopub.status.idle":"2024-09-10T18:27:53.778039Z","shell.execute_reply":"2024-09-10T18:27:53.776890Z","shell.execute_reply.started":"2024-09-10T18:18:03.573971Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 626/626 [00:50<00:00, 12.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","Train Loss: 6.1365\n","Train Perplexity: 462.4178\n","Val Loss: 5.4839\n","Val Perplexity: 240.7912\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 626/626 [00:51<00:00, 12.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/10\n","Train Loss: 5.4135\n","Train Perplexity: 224.4158\n","Val Loss: 5.2455\n","Val Perplexity: 189.7049\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 626/626 [00:53<00:00, 11.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/10\n","Train Loss: 5.2076\n","Train Perplexity: 182.6506\n","Val Loss: 5.1691\n","Val Perplexity: 175.7632\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 626/626 [00:53<00:00, 11.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/10\n","Train Loss: 5.0820\n","Train Perplexity: 161.0890\n","Val Loss: 5.1350\n","Val Perplexity: 169.8612\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 626/626 [00:54<00:00, 11.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/10\n","Train Loss: 4.9842\n","Train Perplexity: 146.0835\n","Val Loss: 5.1239\n","Val Perplexity: 167.9931\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 626/626 [00:54<00:00, 11.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6/10\n","Train Loss: 4.9058\n","Train Perplexity: 135.0648\n","Val Loss: 5.1227\n","Val Perplexity: 167.7800\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 626/626 [00:54<00:00, 11.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/10\n","Train Loss: 4.8431\n","Train Perplexity: 126.8569\n","Val Loss: 5.1245\n","Val Perplexity: 168.0902\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 626/626 [00:55<00:00, 11.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8/10\n","Train Loss: 4.6563\n","Train Perplexity: 105.2445\n","Val Loss: 5.1105\n","Val Perplexity: 165.7612\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 626/626 [00:55<00:00, 11.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9/10\n","Train Loss: 4.6226\n","Train Perplexity: 101.7620\n","Val Loss: 5.1147\n","Val Perplexity: 166.4530\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 626/626 [00:55<00:00, 11.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/10\n","Train Loss: 4.5889\n","Train Perplexity: 98.3876\n","Val Loss: 5.1172\n","Val Perplexity: 166.8755\n"]}],"source":["model = train_model_transformer(model, train_loader, val_loader, optimizer, criterion, scheduler, num_epochs=10, patience=3, pad_idx=pad_idx)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Perplexity Scores"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:28:03.572416Z","iopub.status.busy":"2024-09-10T18:28:03.571538Z","iopub.status.idle":"2024-09-10T18:28:20.804831Z","shell.execute_reply":"2024-09-10T18:28:20.803869Z","shell.execute_reply.started":"2024-09-10T18:28:03.572374Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Train Loss: 4.503557234145582\n","Train Perplexity: 90.3379135131836\n"]}],"source":["loss, perplexity = test_model_transformer(model, train_loader, criterion, pad_idx)\n","print(f'\\nTrain Loss: {loss}')\n","print(f'Train Perplexity: {perplexity}')"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:28:20.806712Z","iopub.status.busy":"2024-09-10T18:28:20.806398Z","iopub.status.idle":"2024-09-10T18:28:25.701080Z","shell.execute_reply":"2024-09-10T18:28:25.700080Z","shell.execute_reply.started":"2024-09-10T18:28:20.806680Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Val Loss: 5.1189669630380985\n","Val Perplexity: 167.16261291503906\n"]}],"source":["loss, perplexity = test_model_transformer(model, val_loader, criterion, pad_idx)\n","print(f'\\nVal Loss: {loss}')\n","print(f'Val Perplexity: {perplexity}')"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:28:25.702708Z","iopub.status.busy":"2024-09-10T18:28:25.702394Z","iopub.status.idle":"2024-09-10T18:28:28.115630Z","shell.execute_reply":"2024-09-10T18:28:28.114621Z","shell.execute_reply.started":"2024-09-10T18:28:25.702675Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Test Loss: 5.129219749238756\n","Test Perplexity: 168.88525390625\n"]}],"source":["loss, perplexity = test_model_transformer(model, test_loader, criterion, pad_idx)\n","print(f'\\nTest Loss: {loss}')\n","print(f'Test Perplexity: {perplexity}')"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:28:34.586354Z","iopub.status.busy":"2024-09-10T18:28:34.585633Z","iopub.status.idle":"2024-09-10T18:32:49.235194Z","shell.execute_reply":"2024-09-10T18:32:49.234130Z","shell.execute_reply.started":"2024-09-10T18:28:34.586295Z"},"trusted":true},"outputs":[{"data":{"text/plain":["267.76079880280355"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["save_perplexities_transformer(model, encoded_train, criterion, '2021101072_LM3_train_perplexity.txt', vocab, pad_idx)\n","save_perplexities_transformer(model, encoded_val, criterion, '2021101072_LM3_val_perplexity.txt', vocab, pad_idx)\n","save_perplexities_transformer(model, encoded_test, criterion, '2021101072_LM3_test_perplexity.txt', vocab, pad_idx)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:32:49.237140Z","iopub.status.busy":"2024-09-10T18:32:49.236812Z","iopub.status.idle":"2024-09-10T18:32:49.241959Z","shell.execute_reply":"2024-09-10T18:32:49.240902Z","shell.execute_reply.started":"2024-09-10T18:32:49.237108Z"},"trusted":true},"outputs":[],"source":["# save_model(model, '2021101072_LM3.pt')"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:40:19.698459Z","iopub.status.busy":"2024-09-10T18:40:19.697461Z","iopub.status.idle":"2024-09-10T18:40:19.809118Z","shell.execute_reply":"2024-09-10T18:40:19.808077Z","shell.execute_reply.started":"2024-09-10T18:40:19.698406Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Data saved successfully!\n"]}],"source":["import pickle\n","\n","with open('data_store_transformer.pkl', 'wb') as f:\n","    pickle.dump({\n","        'embeddings': embeddings,\n","        'vocab': vocab,\n","        'word_to_idx': word_to_idx,\n","        'encoded_train': encoded_train,\n","        'encoded_val': encoded_val,\n","        'encoded_test': encoded_test,\n","    }, f)\n","\n","print(\"Data saved successfully!\")"]},{"cell_type":"markdown","metadata":{},"source":["## Loading and Running the model again"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:42:39.420877Z","iopub.status.busy":"2024-09-10T18:42:39.419910Z","iopub.status.idle":"2024-09-10T18:42:39.570543Z","shell.execute_reply":"2024-09-10T18:42:39.569564Z","shell.execute_reply.started":"2024-09-10T18:42:39.420835Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Data loaded successfully!\n"]}],"source":["with open('/kaggle/working/data_store_transformer.pkl', 'rb') as f:\n","    data = pickle.load(f)\n","\n","embeddings = data['embeddings']\n","vocab = data['vocab']\n","word_to_idx = data['word_to_idx']\n","encoded_train = data['encoded_train']\n","encoded_val = data['encoded_val']\n","encoded_test = data['encoded_test']\n","\n","# Recreate datasets and loaders\n","train_dataset = TransformerDataset(encoded_train)\n","val_dataset = TransformerDataset(encoded_val)\n","test_dataset = TransformerDataset(encoded_test)\n","\n","pad_idx = word_to_idx['<PAD>']\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, collate_fn=lambda batch: collate_fn(batch, pad_idx), shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, collate_fn=lambda batch: collate_fn(batch, pad_idx), shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, collate_fn=lambda batch: collate_fn(batch, pad_idx), shuffle=True)\n","\n","print(\"Data loaded successfully!\")"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:42:57.414312Z","iopub.status.busy":"2024-09-10T18:42:57.413922Z","iopub.status.idle":"2024-09-10T18:42:57.520607Z","shell.execute_reply":"2024-09-10T18:42:57.519723Z","shell.execute_reply.started":"2024-09-10T18:42:57.414277Z"},"trusted":true},"outputs":[],"source":["vocab_size = len(vocab)\n","embedding_dim = 300\n","num_heads = 10\n","num_layers = 2\n","hidden_dim = 300\n","dropout = 0.1\n","\n","model_new = TransformerDecoder(embedding=embeddings, vocab_size=vocab_size, embedding_dim=embedding_dim, num_heads=num_heads, num_layers=num_layers, hidden_dim=hidden_dim, dropout=dropout).to(device)\n","model_new.load_state_dict(torch.load('/kaggle/working/2021101072_LM3.pt', weights_only=True))\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n","optimizer = optim.AdamW(model_new.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=0, factor=0.1)"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:43:00.642743Z","iopub.status.busy":"2024-09-10T18:43:00.641853Z","iopub.status.idle":"2024-09-10T18:43:05.241241Z","shell.execute_reply":"2024-09-10T18:43:05.240244Z","shell.execute_reply.started":"2024-09-10T18:43:00.642701Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Val Loss: 5.109053129590423\n","Val Perplexity: 165.51356506347656\n"]}],"source":["loss, perplexity = test_model_transformer(model_new, val_loader, criterion, pad_idx)\n","print(f'\\nVal Loss: {loss}')\n","print(f'Val Perplexity: {perplexity}')"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T18:43:05.244200Z","iopub.status.busy":"2024-09-10T18:43:05.243388Z","iopub.status.idle":"2024-09-10T18:43:07.474495Z","shell.execute_reply":"2024-09-10T18:43:07.473382Z","shell.execute_reply.started":"2024-09-10T18:43:05.244149Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Test Loss: 5.117912377251519\n","Test Perplexity: 166.98638916015625\n"]}],"source":["loss, perplexity = test_model_transformer(model_new, test_loader, criterion, pad_idx)\n","print(f'\\nTest Loss: {loss}')\n","print(f'Test Perplexity: {perplexity}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5656320,"sourceId":9334570,"sourceType":"datasetVersion"},{"datasetId":5656337,"sourceId":9334625,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
